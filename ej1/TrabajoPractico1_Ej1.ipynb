{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 1"
      ],
      "metadata": {
        "id": "ZPz3G8GdQ6ii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduccion"
      ],
      "metadata": {
        "id": "hMtiKw_hQ_KP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El dataset que subimos consiste en un diccionario que consta de tres elementos:\n",
        "\n",
        "`tiempos_disparos` es una lista de 1000 elementos. Cada elemento corresponde a los tiempos de disparo de una neurona (unidades en $s$).\n",
        "\n",
        "`velocidades` es un vector con valores de velocidad en el tiempo (unidades en $m/s$).\n",
        "\n",
        "`tiempos_velocidades` es un vector de tiempos correspondiente a cada valor de velocidad (unidades en $s$).\n",
        "\n",
        "El dataset fue simulado generando un vector de velocidad de forma aleatoria (de tipo *random walk* gaussiano) y trenes de disparos independientes provenientes de un proceso de Poisson no estacionario (para quienes le interese, ya lo vamos a ver pero [aca](https://elephant.readthedocs.io/en/latest/index.html) pueden aprender de una libreria muy piola para hacerlo). Esto ultimo quiere decir que generamos disparos de neuronas independientes mediante distribuciones de Poisson cuyas medias de disparo $\\lambda$ variaban en el tiempo en funcion de la velocidad $v$ siguiendo un modelo mas o menos como este\n",
        "\n",
        "\n",
        "\n",
        "$$\\lambda_i(v) = r_i + \\alpha_i\\left[v-v_{i}^{th}\\right]^+ $$\n",
        "\n",
        "donde la operacion $[\\alpha]^+=\\alpha$ si $\\alpha>0$ y $[\\alpha]^+=0$ si $\\alpha<0$. Lo importante es que es un modelo de respuesta lineal a la velocidad, algo relativamente verosimil a lo que se ve en varios tipos de neuronas que codifican velocidad en distintas partes del cerebro (aunque bastante muy de juguete).\n",
        "\n",
        "La idea de este ejercicio es que sea bastante guiado para que tengan un primer appoach algo metodico para ver y aplicar PCA, pero la posta va a estar en el ejercicio 2."
      ],
      "metadata": {
        "id": "QVPNOwyOaEcd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importamos librerias utiles (pueden usar las que quieran)"
      ],
      "metadata": {
        "id": "lrooHRLXRvLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pylab as plt"
      ],
      "metadata": {
        "id": "vR744Dd4RqoC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Primero, descarguen la data y carguenla en el notebook."
      ],
      "metadata": {
        "id": "6oVXwnuCgREo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "mypath = ... #aca pongan la direccion del archivo\n",
        "\n",
        "with open(mypath+'DataTP1.pkl', 'rb') as fp:\n",
        "    data = pickle.load(fp)"
      ],
      "metadata": {
        "id": "Qh8R120rW3eD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tiempos_disparos = data['tiempos_disparos']\n",
        "tiempos_velocidades = data['tiempos_velocidades']\n",
        "velocidades = data['velocidades']"
      ],
      "metadata": {
        "id": "a285OAz3SHLo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inciso (a)\n",
        "\n",
        "- Realizar un rasterplot de los trenes de disparo en el tiempo\n",
        "- Visualizar velocidad vs. tiempo"
      ],
      "metadata": {
        "id": "dE5evCwpPorY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UM_Yegf2PuKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inciso (b)\n",
        "\n",
        "Pasar los disparos a tasas de disparo realizando un promedio móvil con una ventana temporal adecuada\n",
        "\n"
      ],
      "metadata": {
        "id": "K2AkzpafPuiY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tuo75bi1P-VY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hint\n",
        "\n",
        "#La idea aca es que bineen la data y sumen la cantidad de disparos por cada bin\n",
        "#temporal (y lo mismo con el vector de velocidades). Hay muchas formas de hacer-\n",
        "#lo, aca les dejamos una\n",
        "\n",
        "#(1) Definan un bin temporal que les parezca razonable. La data esta en segundos,\n",
        "#asi que una forma de estimar el sampling rate de los datos es calculando la\n",
        "#media de la diferencia entre tiempos de mediciones consecutivas\n",
        "dt = np.mean(np.diff(tiempos_velocidades))\n",
        "\n",
        "N = len(tiempos_disparos) #numero de neuronas\n",
        "\n",
        "#dado que el dt es de 10ms, promediar de a un segundo nos garantiza juntar varios\n",
        "#disparos por bin\n",
        "ancho_bin = 1\n",
        "\n",
        "#Como los tiempos de las velocidades estan equiespaciados, los sampleamos con el\n",
        "#ancho elegido\n",
        "bin_tiempos_velocidades = tiempos_velocidades[::int(ancho_bin/dt)]\n",
        "bin_velocidades = [np.mean(velocidades[i*int(ancho_bin/dt):(i+1)*int(ancho_bin/dt)]) for i in range(len(bin_tiempos_velocidades)-1)] #velocidad media por bin\n",
        "\n",
        "#Calculamos y almacenamos las tasas de disparo en una matriz\n",
        "tasa_disparo = np.zeros((N,len(bin_tiempos_velocidades)-1))\n",
        "for n in range(tasa_disparo.shape[0]):\n",
        "  tasa_disparo[n,:], _ = np.histogram(tiempos_disparos[n], bins=bin_tiempos_velocidades)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "IEHvVOn4P-vK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inciso (c)\n",
        "\n",
        "Usando los datos del punto (b), visualizar la respuesta de las neuronas a las distintas velocidades ¿Todas responden de la misma forma?"
      ],
      "metadata": {
        "id": "a7GjY9PwTFUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fijate en estas neuronas\n",
        "indices_de_neuronas = [44, 207, 331, 643, 656, 660, 699, 779]"
      ],
      "metadata": {
        "id": "ScKbbbrYTUyr"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inciso (d)\n",
        "\n",
        "Aplicar PCA sobre los datos del punto b y graficar la varianza explicada cumulativa ¿Cuántas dimensiones esperas que sean necesarias para capturar la dinámica relevante del problema?\n"
      ],
      "metadata": {
        "id": "EklsWvGQTUFj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eaEIan1RTft-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inciso (e)\n",
        "\n",
        "Visualizar en 2D\n",
        " - PC1 vs. PC2\n",
        " - PC1 vs. Velocidad\n",
        " - PC1 vs. tiempo\n",
        "\n",
        "¿Tiene sentido en base a lo esperado?"
      ],
      "metadata": {
        "id": "kwIdb_Z3VyNL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FjQGT4QEXni1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}